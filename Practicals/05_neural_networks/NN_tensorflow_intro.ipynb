{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:39:28.286752Z",
     "start_time": "2023-04-11T15:39:21.263465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.22.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.8)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.1)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:36:41.353577Z",
     "start_time": "2023-04-17T12:36:25.112987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 14:36:29.925960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:36:51.801366Z",
     "start_time": "2023-04-17T12:36:49.182624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:08.152833Z",
     "start_time": "2023-04-11T15:41:08.100392Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:08.619152Z",
     "start_time": "2023-04-11T15:41:08.577510Z"
    }
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:08.869953Z",
     "start_time": "2023-04-11T15:41:08.844236Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:09.117487Z",
     "start_time": "2023-04-11T15:41:09.110373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (12800, 8), target_ratio: 0.502\n",
      "test size: (4000, 8), target_ratio: 0.501\n",
      "dev size: (3200, 8), target_ratio: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but <span style=\"color:red\"> NOT </span> appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:13.838758Z",
     "start_time": "2023-04-11T15:41:13.628907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                90        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:16.870950Z",
     "start_time": "2023-04-11T15:41:16.723694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:20.713610Z",
     "start_time": "2023-04-11T15:41:20.644690Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:22.113370Z",
     "start_time": "2023-04-11T15:41:21.908495Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid (TFOpLambda  (None, 1)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:24.407551Z",
     "start_time": "2023-04-11T15:41:24.385606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:51.935631Z",
     "start_time": "2023-04-11T15:41:51.891346Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:41:53.646922Z",
     "start_time": "2023-04-11T15:41:53.624036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Bias of the last layers:\n",
      "[0.]\n",
      "\n",
      ">>> Kernel of the last layers:\n",
      "[[-0.56460613]\n",
      " [ 0.29604632]\n",
      " [ 0.21662462]\n",
      " [-0.6775259 ]\n",
      " [ 0.30738193]\n",
      " [-0.31533614]\n",
      " [-0.17806965]\n",
      " [-0.2903523 ]\n",
      " [ 0.17737854]\n",
      " [ 0.5742884 ]]\n",
      "\n",
      ">>> Bias of the first layers:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      ">>> Kernel of the first layers:\n",
      "[[-1.9635808e-01  4.0544736e-01 -3.5376328e-01  1.5955198e-01\n",
      "  -5.0685287e-02 -7.6352417e-02  2.4730825e-01  3.3675057e-01\n",
      "  -4.0275934e-01  3.2808918e-01]\n",
      " [ 2.3958725e-01  2.8455967e-01 -5.0527781e-01 -2.6963496e-01\n",
      "  -7.9658508e-02  4.7420633e-01  5.5414319e-02  2.0938939e-01\n",
      "   3.5862774e-01 -5.7387954e-01]\n",
      " [ 5.1212227e-01 -3.6785352e-01  4.4393539e-04  8.4377170e-02\n",
      "   2.7562928e-01  1.5110874e-01 -3.5856718e-01  4.6589088e-01\n",
      "   3.3835709e-02  5.6500971e-01]\n",
      " [-2.1937844e-01  3.5303003e-01  3.8683599e-01 -1.6998386e-01\n",
      "   2.5893134e-01  2.9614133e-01  3.0482227e-01  4.0505934e-01\n",
      "  -2.8401744e-01  2.7615428e-01]\n",
      " [-3.5402387e-01 -3.9353395e-01  2.9713529e-01 -1.6215485e-01\n",
      "   5.6220460e-01 -4.6641812e-01 -3.8180447e-01 -5.7619494e-01\n",
      "  -4.6975464e-01 -5.0485951e-01]\n",
      " [ 2.2124404e-01  2.8420216e-01 -5.8273077e-02  3.4534264e-01\n",
      "   8.7922096e-02  2.3525798e-01 -3.5070840e-01 -7.8585535e-02\n",
      "   4.3619418e-01  4.8770916e-01]\n",
      " [ 2.3034084e-01 -5.4026306e-01  7.9708099e-03  3.1156486e-01\n",
      "   1.3542426e-01 -1.2115988e-01  3.1107467e-01  2.9374468e-01\n",
      "  -5.5623567e-01  1.9116771e-01]\n",
      " [ 5.3378487e-01  5.7474649e-01  2.7616996e-01  5.1154137e-02\n",
      "  -2.4562958e-01 -9.7154915e-02 -1.5123114e-01  1.7697644e-01\n",
      "  -3.7167799e-01  4.3668675e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:')\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:51:12.698211Z",
     "start_time": "2023-04-11T15:50:14.282103Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6721 - auc: 0.6333 - binary_accuracy: 0.5921\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5180 - auc: 0.8405 - binary_accuracy: 0.7606\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4370 - auc: 0.8913 - binary_accuracy: 0.8145\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3860 - auc: 0.9148 - binary_accuracy: 0.8426\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3548 - auc: 0.9276 - binary_accuracy: 0.8594\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3352 - auc: 0.9348 - binary_accuracy: 0.8683\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3231 - auc: 0.9386 - binary_accuracy: 0.8743\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3143 - auc: 0.9414 - binary_accuracy: 0.8773\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3077 - auc: 0.9436 - binary_accuracy: 0.8797\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3011 - auc: 0.9457 - binary_accuracy: 0.8832\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2949 - auc: 0.9477 - binary_accuracy: 0.8863\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2879 - auc: 0.9502 - binary_accuracy: 0.8895\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2812 - auc: 0.9525 - binary_accuracy: 0.8920\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2751 - auc: 0.9546 - binary_accuracy: 0.8948\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2698 - auc: 0.9566 - binary_accuracy: 0.8963\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2653 - auc: 0.9579 - binary_accuracy: 0.8993\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2611 - auc: 0.9593 - binary_accuracy: 0.9003\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2577 - auc: 0.9603 - binary_accuracy: 0.9027\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2548 - auc: 0.9613 - binary_accuracy: 0.9020\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2518 - auc: 0.9621 - binary_accuracy: 0.9032\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2493 - auc: 0.9628 - binary_accuracy: 0.9047\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2467 - auc: 0.9636 - binary_accuracy: 0.9056\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2444 - auc: 0.9644 - binary_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2422 - auc: 0.9649 - binary_accuracy: 0.9081\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2403 - auc: 0.9655 - binary_accuracy: 0.9078\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2386 - auc: 0.9659 - binary_accuracy: 0.9085\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2373 - auc: 0.9663 - binary_accuracy: 0.9094\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2355 - auc: 0.9668 - binary_accuracy: 0.9098\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2341 - auc: 0.9672 - binary_accuracy: 0.9114\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2327 - auc: 0.9676 - binary_accuracy: 0.9099\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2313 - auc: 0.9680 - binary_accuracy: 0.9101\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2298 - auc: 0.9684 - binary_accuracy: 0.9120\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2288 - auc: 0.9687 - binary_accuracy: 0.9119\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2273 - auc: 0.9691 - binary_accuracy: 0.9123\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2260 - auc: 0.9695 - binary_accuracy: 0.9127\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2249 - auc: 0.9697 - binary_accuracy: 0.9130\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2237 - auc: 0.9701 - binary_accuracy: 0.9137\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2227 - auc: 0.9704 - binary_accuracy: 0.9141\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2216 - auc: 0.9707 - binary_accuracy: 0.9149\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2207 - auc: 0.9709 - binary_accuracy: 0.9146\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2197 - auc: 0.9712 - binary_accuracy: 0.9155\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2188 - auc: 0.9715 - binary_accuracy: 0.9159\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2180 - auc: 0.9717 - binary_accuracy: 0.9175\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2172 - auc: 0.9719 - binary_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2164 - auc: 0.9721 - binary_accuracy: 0.9165\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2159 - auc: 0.9722 - binary_accuracy: 0.9169\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2151 - auc: 0.9724 - binary_accuracy: 0.9163\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2144 - auc: 0.9726 - binary_accuracy: 0.9180\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2137 - auc: 0.9728 - binary_accuracy: 0.9187\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2132 - auc: 0.9730 - binary_accuracy: 0.9183\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2126 - auc: 0.9731 - binary_accuracy: 0.9185\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2119 - auc: 0.9733 - binary_accuracy: 0.9195\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2111 - auc: 0.9735 - binary_accuracy: 0.9199\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2105 - auc: 0.9737 - binary_accuracy: 0.9203\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2100 - auc: 0.9738 - binary_accuracy: 0.9198\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2089 - auc: 0.9740 - binary_accuracy: 0.9209\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2085 - auc: 0.9742 - binary_accuracy: 0.9223\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2077 - auc: 0.9744 - binary_accuracy: 0.9224\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2071 - auc: 0.9746 - binary_accuracy: 0.9218\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2065 - auc: 0.9747 - binary_accuracy: 0.9221\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2060 - auc: 0.9749 - binary_accuracy: 0.9234\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2055 - auc: 0.9750 - binary_accuracy: 0.9234\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2049 - auc: 0.9751 - binary_accuracy: 0.9233\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2040 - auc: 0.9753 - binary_accuracy: 0.9227\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2035 - auc: 0.9755 - binary_accuracy: 0.9245\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2027 - auc: 0.9756 - binary_accuracy: 0.9249\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2025 - auc: 0.9757 - binary_accuracy: 0.9234\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2018 - auc: 0.9759 - binary_accuracy: 0.9255\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2011 - auc: 0.9761 - binary_accuracy: 0.9255\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2008 - auc: 0.9761 - binary_accuracy: 0.9253\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.1999 - auc: 0.9763 - binary_accuracy: 0.9250\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.1996 - auc: 0.9765 - binary_accuracy: 0.9257\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.1990 - auc: 0.9764 - binary_accuracy: 0.9262\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.1985 - auc: 0.9767 - binary_accuracy: 0.9263\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1980 - auc: 0.9769 - binary_accuracy: 0.9266\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1975 - auc: 0.9770 - binary_accuracy: 0.9263\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1971 - auc: 0.9771 - binary_accuracy: 0.9273\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1967 - auc: 0.9772 - binary_accuracy: 0.9270\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1958 - auc: 0.9773 - binary_accuracy: 0.9267\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1956 - auc: 0.9774 - binary_accuracy: 0.9280\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1951 - auc: 0.9776 - binary_accuracy: 0.9284\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1949 - auc: 0.9775 - binary_accuracy: 0.9281\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1944 - auc: 0.9776 - binary_accuracy: 0.9287\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1939 - auc: 0.9778 - binary_accuracy: 0.9295\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1939 - auc: 0.9778 - binary_accuracy: 0.9295\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1930 - auc: 0.9780 - binary_accuracy: 0.9295\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1928 - auc: 0.9780 - binary_accuracy: 0.9298\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1924 - auc: 0.9782 - binary_accuracy: 0.9305\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1920 - auc: 0.9783 - binary_accuracy: 0.9305\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1912 - auc: 0.9784 - binary_accuracy: 0.9312\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1915 - auc: 0.9785 - binary_accuracy: 0.9316\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1911 - auc: 0.9785 - binary_accuracy: 0.9316\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1907 - auc: 0.9786 - binary_accuracy: 0.9318\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1903 - auc: 0.9787 - binary_accuracy: 0.9316\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1901 - auc: 0.9787 - binary_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1900 - auc: 0.9788 - binary_accuracy: 0.9320\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1895 - auc: 0.9789 - binary_accuracy: 0.9334\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1890 - auc: 0.9790 - binary_accuracy: 0.9328\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1890 - auc: 0.9790 - binary_accuracy: 0.9334\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1885 - auc: 0.9792 - binary_accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd67d706e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:51:25.105905Z",
     "start_time": "2023-04-11T15:51:24.077523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2066 - auc: 0.9743 - binary_accuracy: 0.9315\n",
      "125/125 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:51:31.290769Z",
     "start_time": "2023-04-11T15:51:31.278619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.33\n",
      "0 - 0.19\n",
      "0 - 0.55\n",
      "1 - 0.99\n",
      "0 - 0.00\n",
      "0 - 0.00\n",
      "1 - 0.98\n",
      "0 - 0.00\n",
      "1 - 1.00\n",
      "1 - 1.00\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:51:40.431305Z",
     "start_time": "2023-04-11T15:51:40.188586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RegularizedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid_1 (TFOpLamb  (None, 1)                0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:53:19.326388Z",
     "start_time": "2023-04-11T15:51:44.276384Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 2s 3ms/step - loss: 0.5258 - auc_1: 0.8369 - binary_accuracy: 0.7527 - val_loss: 0.4314 - val_auc_1: 0.9059 - val_binary_accuracy: 0.8325\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.4007 - auc_1: 0.9154 - binary_accuracy: 0.8416 - val_loss: 0.3614 - val_auc_1: 0.9344 - val_binary_accuracy: 0.8681\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3503 - auc_1: 0.9365 - binary_accuracy: 0.8709 - val_loss: 0.3292 - val_auc_1: 0.9452 - val_binary_accuracy: 0.8828\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3259 - auc_1: 0.9449 - binary_accuracy: 0.8822 - val_loss: 0.3143 - val_auc_1: 0.9494 - val_binary_accuracy: 0.8888\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3130 - auc_1: 0.9490 - binary_accuracy: 0.8895 - val_loss: 0.3052 - val_auc_1: 0.9521 - val_binary_accuracy: 0.8925\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3049 - auc_1: 0.9517 - binary_accuracy: 0.8916 - val_loss: 0.2994 - val_auc_1: 0.9537 - val_binary_accuracy: 0.8950\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2989 - auc_1: 0.9536 - binary_accuracy: 0.8951 - val_loss: 0.2955 - val_auc_1: 0.9550 - val_binary_accuracy: 0.8972\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2939 - auc_1: 0.9554 - binary_accuracy: 0.8977 - val_loss: 0.2914 - val_auc_1: 0.9561 - val_binary_accuracy: 0.8994\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2896 - auc_1: 0.9569 - binary_accuracy: 0.8982 - val_loss: 0.2885 - val_auc_1: 0.9575 - val_binary_accuracy: 0.8966\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2860 - auc_1: 0.9582 - binary_accuracy: 0.8988 - val_loss: 0.2857 - val_auc_1: 0.9584 - val_binary_accuracy: 0.8966\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2827 - auc_1: 0.9595 - binary_accuracy: 0.9010 - val_loss: 0.2826 - val_auc_1: 0.9596 - val_binary_accuracy: 0.8975\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2795 - auc_1: 0.9607 - binary_accuracy: 0.9009 - val_loss: 0.2806 - val_auc_1: 0.9609 - val_binary_accuracy: 0.8947\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2766 - auc_1: 0.9618 - binary_accuracy: 0.9010 - val_loss: 0.2773 - val_auc_1: 0.9619 - val_binary_accuracy: 0.8978\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2742 - auc_1: 0.9628 - binary_accuracy: 0.9024 - val_loss: 0.2745 - val_auc_1: 0.9625 - val_binary_accuracy: 0.8966\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2719 - auc_1: 0.9636 - binary_accuracy: 0.9045 - val_loss: 0.2725 - val_auc_1: 0.9638 - val_binary_accuracy: 0.8966\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2698 - auc_1: 0.9644 - binary_accuracy: 0.9052 - val_loss: 0.2697 - val_auc_1: 0.9647 - val_binary_accuracy: 0.9000\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2681 - auc_1: 0.9651 - binary_accuracy: 0.9055 - val_loss: 0.2679 - val_auc_1: 0.9651 - val_binary_accuracy: 0.9019\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2665 - auc_1: 0.9656 - binary_accuracy: 0.9063 - val_loss: 0.2669 - val_auc_1: 0.9659 - val_binary_accuracy: 0.9013\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2649 - auc_1: 0.9663 - binary_accuracy: 0.9066 - val_loss: 0.2654 - val_auc_1: 0.9661 - val_binary_accuracy: 0.9025\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2638 - auc_1: 0.9668 - binary_accuracy: 0.9077 - val_loss: 0.2633 - val_auc_1: 0.9670 - val_binary_accuracy: 0.9028\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2626 - auc_1: 0.9671 - binary_accuracy: 0.9076 - val_loss: 0.2626 - val_auc_1: 0.9670 - val_binary_accuracy: 0.9069\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2617 - auc_1: 0.9674 - binary_accuracy: 0.9090 - val_loss: 0.2616 - val_auc_1: 0.9677 - val_binary_accuracy: 0.9062\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2607 - auc_1: 0.9679 - binary_accuracy: 0.9092 - val_loss: 0.2612 - val_auc_1: 0.9679 - val_binary_accuracy: 0.9053\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2603 - auc_1: 0.9681 - binary_accuracy: 0.9091 - val_loss: 0.2607 - val_auc_1: 0.9678 - val_binary_accuracy: 0.9066\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2596 - auc_1: 0.9683 - binary_accuracy: 0.9102 - val_loss: 0.2599 - val_auc_1: 0.9681 - val_binary_accuracy: 0.9069\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2590 - auc_1: 0.9686 - binary_accuracy: 0.9101 - val_loss: 0.2603 - val_auc_1: 0.9685 - val_binary_accuracy: 0.9075\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2585 - auc_1: 0.9688 - binary_accuracy: 0.9110 - val_loss: 0.2597 - val_auc_1: 0.9688 - val_binary_accuracy: 0.9053\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2579 - auc_1: 0.9693 - binary_accuracy: 0.9130 - val_loss: 0.2581 - val_auc_1: 0.9688 - val_binary_accuracy: 0.9087\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2572 - auc_1: 0.9694 - binary_accuracy: 0.9115 - val_loss: 0.2576 - val_auc_1: 0.9691 - val_binary_accuracy: 0.9106\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2566 - auc_1: 0.9697 - binary_accuracy: 0.9140 - val_loss: 0.2576 - val_auc_1: 0.9692 - val_binary_accuracy: 0.9091\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2560 - auc_1: 0.9699 - binary_accuracy: 0.9136 - val_loss: 0.2559 - val_auc_1: 0.9695 - val_binary_accuracy: 0.9116\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2554 - auc_1: 0.9701 - binary_accuracy: 0.9136 - val_loss: 0.2565 - val_auc_1: 0.9702 - val_binary_accuracy: 0.9112\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2545 - auc_1: 0.9707 - binary_accuracy: 0.9152 - val_loss: 0.2552 - val_auc_1: 0.9702 - val_binary_accuracy: 0.9112\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2535 - auc_1: 0.9711 - binary_accuracy: 0.9164 - val_loss: 0.2549 - val_auc_1: 0.9711 - val_binary_accuracy: 0.9106\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2526 - auc_1: 0.9715 - binary_accuracy: 0.9177 - val_loss: 0.2517 - val_auc_1: 0.9715 - val_binary_accuracy: 0.9144\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2514 - auc_1: 0.9720 - binary_accuracy: 0.9175 - val_loss: 0.2504 - val_auc_1: 0.9716 - val_binary_accuracy: 0.9166\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2500 - auc_1: 0.9724 - binary_accuracy: 0.9180 - val_loss: 0.2500 - val_auc_1: 0.9715 - val_binary_accuracy: 0.9134\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2492 - auc_1: 0.9726 - binary_accuracy: 0.9191 - val_loss: 0.2486 - val_auc_1: 0.9725 - val_binary_accuracy: 0.9159\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2482 - auc_1: 0.9730 - binary_accuracy: 0.9197 - val_loss: 0.2487 - val_auc_1: 0.9730 - val_binary_accuracy: 0.9162\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2476 - auc_1: 0.9733 - binary_accuracy: 0.9212 - val_loss: 0.2467 - val_auc_1: 0.9732 - val_binary_accuracy: 0.9194\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2467 - auc_1: 0.9736 - binary_accuracy: 0.9211 - val_loss: 0.2466 - val_auc_1: 0.9733 - val_binary_accuracy: 0.9181\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2463 - auc_1: 0.9738 - binary_accuracy: 0.9228 - val_loss: 0.2459 - val_auc_1: 0.9732 - val_binary_accuracy: 0.9197\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2457 - auc_1: 0.9738 - binary_accuracy: 0.9220 - val_loss: 0.2452 - val_auc_1: 0.9738 - val_binary_accuracy: 0.9206\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2449 - auc_1: 0.9744 - binary_accuracy: 0.9239 - val_loss: 0.2461 - val_auc_1: 0.9734 - val_binary_accuracy: 0.9197\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2444 - auc_1: 0.9743 - binary_accuracy: 0.9238 - val_loss: 0.2461 - val_auc_1: 0.9736 - val_binary_accuracy: 0.9187\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2442 - auc_1: 0.9745 - binary_accuracy: 0.9232 - val_loss: 0.2452 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9219\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2439 - auc_1: 0.9747 - binary_accuracy: 0.9239 - val_loss: 0.2438 - val_auc_1: 0.9741 - val_binary_accuracy: 0.9222\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2434 - auc_1: 0.9747 - binary_accuracy: 0.9247 - val_loss: 0.2447 - val_auc_1: 0.9741 - val_binary_accuracy: 0.9194\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2433 - auc_1: 0.9750 - binary_accuracy: 0.9248 - val_loss: 0.2440 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9247\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2429 - auc_1: 0.9750 - binary_accuracy: 0.9238 - val_loss: 0.2443 - val_auc_1: 0.9739 - val_binary_accuracy: 0.9222\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2429 - auc_1: 0.9750 - binary_accuracy: 0.9248 - val_loss: 0.2434 - val_auc_1: 0.9742 - val_binary_accuracy: 0.9231\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2425 - auc_1: 0.9752 - binary_accuracy: 0.9268 - val_loss: 0.2435 - val_auc_1: 0.9743 - val_binary_accuracy: 0.9250\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2424 - auc_1: 0.9752 - binary_accuracy: 0.9260 - val_loss: 0.2428 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9237\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2419 - auc_1: 0.9755 - binary_accuracy: 0.9265 - val_loss: 0.2434 - val_auc_1: 0.9743 - val_binary_accuracy: 0.9237\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2416 - auc_1: 0.9756 - binary_accuracy: 0.9266 - val_loss: 0.2433 - val_auc_1: 0.9742 - val_binary_accuracy: 0.9259\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2416 - auc_1: 0.9754 - binary_accuracy: 0.9270 - val_loss: 0.2440 - val_auc_1: 0.9750 - val_binary_accuracy: 0.9244\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2417 - auc_1: 0.9757 - binary_accuracy: 0.9262 - val_loss: 0.2430 - val_auc_1: 0.9744 - val_binary_accuracy: 0.9253\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2415 - auc_1: 0.9756 - binary_accuracy: 0.9267 - val_loss: 0.2432 - val_auc_1: 0.9748 - val_binary_accuracy: 0.9291\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2414 - auc_1: 0.9757 - binary_accuracy: 0.9262 - val_loss: 0.2424 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9253\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2412 - auc_1: 0.9757 - binary_accuracy: 0.9270 - val_loss: 0.2424 - val_auc_1: 0.9749 - val_binary_accuracy: 0.9250\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2409 - auc_1: 0.9759 - binary_accuracy: 0.9273 - val_loss: 0.2429 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9244\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2411 - auc_1: 0.9759 - binary_accuracy: 0.9274 - val_loss: 0.2422 - val_auc_1: 0.9749 - val_binary_accuracy: 0.9241\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2408 - auc_1: 0.9760 - binary_accuracy: 0.9274 - val_loss: 0.2423 - val_auc_1: 0.9748 - val_binary_accuracy: 0.9241\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2407 - auc_1: 0.9759 - binary_accuracy: 0.9270 - val_loss: 0.2421 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9259\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2406 - auc_1: 0.9760 - binary_accuracy: 0.9277 - val_loss: 0.2425 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9262\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2405 - auc_1: 0.9760 - binary_accuracy: 0.9281 - val_loss: 0.2427 - val_auc_1: 0.9752 - val_binary_accuracy: 0.9259\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2406 - auc_1: 0.9760 - binary_accuracy: 0.9285 - val_loss: 0.2421 - val_auc_1: 0.9756 - val_binary_accuracy: 0.9262\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2402 - auc_1: 0.9762 - binary_accuracy: 0.9296 - val_loss: 0.2424 - val_auc_1: 0.9750 - val_binary_accuracy: 0.9278\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2404 - auc_1: 0.9761 - binary_accuracy: 0.9291 - val_loss: 0.2429 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9250\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2403 - auc_1: 0.9762 - binary_accuracy: 0.9291 - val_loss: 0.2416 - val_auc_1: 0.9753 - val_binary_accuracy: 0.9250\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2400 - auc_1: 0.9762 - binary_accuracy: 0.9294 - val_loss: 0.2416 - val_auc_1: 0.9756 - val_binary_accuracy: 0.9269\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2399 - auc_1: 0.9763 - binary_accuracy: 0.9284 - val_loss: 0.2421 - val_auc_1: 0.9752 - val_binary_accuracy: 0.9291\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2402 - auc_1: 0.9763 - binary_accuracy: 0.9298 - val_loss: 0.2430 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9253\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2399 - auc_1: 0.9765 - binary_accuracy: 0.9289 - val_loss: 0.2425 - val_auc_1: 0.9747 - val_binary_accuracy: 0.9287\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2400 - auc_1: 0.9762 - binary_accuracy: 0.9285 - val_loss: 0.2419 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9297\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2398 - auc_1: 0.9764 - binary_accuracy: 0.9298 - val_loss: 0.2421 - val_auc_1: 0.9755 - val_binary_accuracy: 0.9253\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.2399 - auc_1: 0.9765 - binary_accuracy: 0.9300 - val_loss: 0.2419 - val_auc_1: 0.9753 - val_binary_accuracy: 0.9281\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2401 - auc_1: 0.9763 - binary_accuracy: 0.9293 - val_loss: 0.2418 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9281\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.2400 - auc_1: 0.9765 - binary_accuracy: 0.9288 - val_loss: 0.2422 - val_auc_1: 0.9753 - val_binary_accuracy: 0.9272\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2398 - auc_1: 0.9765 - binary_accuracy: 0.9302 - val_loss: 0.2420 - val_auc_1: 0.9752 - val_binary_accuracy: 0.9262\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2397 - auc_1: 0.9765 - binary_accuracy: 0.9298 - val_loss: 0.2419 - val_auc_1: 0.9755 - val_binary_accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd67de00640>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:10:45.431146Z",
     "start_time": "2023-04-11T16:10:14.343066Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4222 - AUC: 0.3181 - binary_accuracy: 0.4266 - val_loss: 1.1172 - val_AUC: 0.3441 - val_binary_accuracy: 0.4150\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9371 - AUC: 0.3946 - binary_accuracy: 0.4161 - val_loss: 0.8267 - val_AUC: 0.4370 - val_binary_accuracy: 0.4284\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7616 - AUC: 0.4931 - binary_accuracy: 0.4731 - val_loss: 0.7232 - val_AUC: 0.5255 - val_binary_accuracy: 0.5056\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6966 - AUC: 0.5700 - binary_accuracy: 0.5573 - val_loss: 0.6790 - val_AUC: 0.5892 - val_binary_accuracy: 0.5884\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6667 - AUC: 0.6232 - binary_accuracy: 0.6128 - val_loss: 0.6554 - val_AUC: 0.6394 - val_binary_accuracy: 0.6281\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6498 - AUC: 0.6609 - binary_accuracy: 0.6344 - val_loss: 0.6409 - val_AUC: 0.6755 - val_binary_accuracy: 0.6503\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6382 - AUC: 0.6880 - binary_accuracy: 0.6489 - val_loss: 0.6302 - val_AUC: 0.7094 - val_binary_accuracy: 0.6625\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6292 - AUC: 0.7152 - binary_accuracy: 0.6604 - val_loss: 0.6215 - val_AUC: 0.7345 - val_binary_accuracy: 0.6741\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6218 - AUC: 0.7365 - binary_accuracy: 0.6672 - val_loss: 0.6140 - val_AUC: 0.7558 - val_binary_accuracy: 0.6762\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6151 - AUC: 0.7554 - binary_accuracy: 0.6736 - val_loss: 0.6071 - val_AUC: 0.7713 - val_binary_accuracy: 0.6797\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7503 - AUC: 0.5920 - binary_accuracy: 0.5739 - val_loss: 0.6540 - val_AUC: 0.7531 - val_binary_accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6086 - AUC: 0.8143 - binary_accuracy: 0.7141 - val_loss: 0.5601 - val_AUC: 0.8605 - val_binary_accuracy: 0.7437\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5449 - AUC: 0.8637 - binary_accuracy: 0.7652 - val_loss: 0.5143 - val_AUC: 0.8835 - val_binary_accuracy: 0.7912\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5104 - AUC: 0.8822 - binary_accuracy: 0.8002 - val_loss: 0.4884 - val_AUC: 0.8967 - val_binary_accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4908 - AUC: 0.8921 - binary_accuracy: 0.8184 - val_loss: 0.4743 - val_AUC: 0.9033 - val_binary_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4796 - AUC: 0.8973 - binary_accuracy: 0.8265 - val_loss: 0.4653 - val_AUC: 0.9088 - val_binary_accuracy: 0.8428\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4724 - AUC: 0.9012 - binary_accuracy: 0.8291 - val_loss: 0.4593 - val_AUC: 0.9111 - val_binary_accuracy: 0.8472\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4671 - AUC: 0.9036 - binary_accuracy: 0.8313 - val_loss: 0.4550 - val_AUC: 0.9133 - val_binary_accuracy: 0.8466\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4633 - AUC: 0.9060 - binary_accuracy: 0.8317 - val_loss: 0.4513 - val_AUC: 0.9148 - val_binary_accuracy: 0.8491\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.4600 - AUC: 0.9079 - binary_accuracy: 0.8350 - val_loss: 0.4484 - val_AUC: 0.9158 - val_binary_accuracy: 0.8491\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 3s 5ms/step - loss: 0.6382 - AUC: 0.8005 - binary_accuracy: 0.7329 - val_loss: 0.6048 - val_AUC: 0.8286 - val_binary_accuracy: 0.7669\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5848 - AUC: 0.8306 - binary_accuracy: 0.7620 - val_loss: 0.5551 - val_AUC: 0.8490 - val_binary_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5470 - AUC: 0.8457 - binary_accuracy: 0.7716 - val_loss: 0.5256 - val_AUC: 0.8597 - val_binary_accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5259 - AUC: 0.8538 - binary_accuracy: 0.7751 - val_loss: 0.5083 - val_AUC: 0.8681 - val_binary_accuracy: 0.7975\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5130 - AUC: 0.8608 - binary_accuracy: 0.7812 - val_loss: 0.4979 - val_AUC: 0.8729 - val_binary_accuracy: 0.8006\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5048 - AUC: 0.8655 - binary_accuracy: 0.7855 - val_loss: 0.4916 - val_AUC: 0.8762 - val_binary_accuracy: 0.8047\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4996 - AUC: 0.8687 - binary_accuracy: 0.7866 - val_loss: 0.4872 - val_AUC: 0.8792 - val_binary_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.4962 - AUC: 0.8712 - binary_accuracy: 0.7899 - val_loss: 0.4844 - val_AUC: 0.8814 - val_binary_accuracy: 0.8075\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4941 - AUC: 0.8731 - binary_accuracy: 0.7894 - val_loss: 0.4827 - val_AUC: 0.8830 - val_binary_accuracy: 0.8091\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4926 - AUC: 0.8745 - binary_accuracy: 0.7909 - val_loss: 0.4816 - val_AUC: 0.8844 - val_binary_accuracy: 0.8081\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 2s 4ms/step - loss: 0.6705 - AUC: 0.7500 - binary_accuracy: 0.6907 - val_loss: 0.5921 - val_AUC: 0.8557 - val_binary_accuracy: 0.7728\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5745 - AUC: 0.8552 - binary_accuracy: 0.7778 - val_loss: 0.5441 - val_AUC: 0.8704 - val_binary_accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5409 - AUC: 0.8656 - binary_accuracy: 0.7891 - val_loss: 0.5179 - val_AUC: 0.8766 - val_binary_accuracy: 0.8062\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5181 - AUC: 0.8744 - binary_accuracy: 0.7987 - val_loss: 0.4980 - val_AUC: 0.8872 - val_binary_accuracy: 0.8138\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5020 - AUC: 0.8837 - binary_accuracy: 0.8036 - val_loss: 0.4868 - val_AUC: 0.8934 - val_binary_accuracy: 0.8216\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4925 - AUC: 0.8894 - binary_accuracy: 0.8117 - val_loss: 0.4799 - val_AUC: 0.8977 - val_binary_accuracy: 0.8272\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.4863 - AUC: 0.8932 - binary_accuracy: 0.8183 - val_loss: 0.4753 - val_AUC: 0.9021 - val_binary_accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.4819 - AUC: 0.8976 - binary_accuracy: 0.8213 - val_loss: 0.4716 - val_AUC: 0.9048 - val_binary_accuracy: 0.8316\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.4786 - AUC: 0.8996 - binary_accuracy: 0.8234 - val_loss: 0.4690 - val_AUC: 0.9080 - val_binary_accuracy: 0.8375\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.4758 - AUC: 0.9030 - binary_accuracy: 0.8254 - val_loss: 0.4672 - val_AUC: 0.9094 - val_binary_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
